{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5641b48a",
   "metadata": {},
   "source": [
    "## 1) Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ea3378",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhistory\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sleep\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'history'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import seaborn as sns\n",
    "import bs4\n",
    "import requests\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import history\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from config import *\n",
    "\n",
    "import ast\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "#client_credentials_manager = SpotifyClientCredentials(client_id='491862eccb624461a90a6ec9a26c94d7', client_secret='342e7a81e01241799d0ff4a6319eaf82')\n",
    "#sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49baece",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = '31cbjrhwwnzm2xs22dqntot7ulyy'\n",
    "client_id ='491862eccb624461a90a6ec9a26c94d7'\n",
    "client_secret = '342e7a81e01241799d0ff4a6319eaf82'\n",
    "redirect_uri = 'http://localhost:7777/callback'\n",
    "scope = 'user-read-recently-played'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccacb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "\n",
    "def get_token(user: str, \n",
    "              client_id: str,\n",
    "              client_secret: str,\n",
    "              redirect_uri: str,\n",
    "              scope: str) -> str:\n",
    "  \n",
    "    token = util.prompt_for_user_token(user,scope,\n",
    "                                               client_id=client_id,\n",
    "                                               client_secret=client_secret,\n",
    "                                               redirect_uri=redirect_uri)\n",
    "    return token\n",
    "        \n",
    "def get_streamings(path: str = 'MyData', \n",
    "                ) -> List[dict]:\n",
    "    \n",
    "    '''Returns a list of streamings form spotify MyData dump.\n",
    "    Will not acquire track features.'''\n",
    "    \n",
    "    files = ['MyData/' + x for x in listdir(path)\n",
    "             if x.split('.')[0][:-1] == 'StreamingHistory']\n",
    "    \n",
    "    all_streamings = []\n",
    "    \n",
    "    for file in files: \n",
    "        with open(file, 'r', encoding='UTF-8') as f:\n",
    "            new_streamings = ast.literal_eval(f.read())\n",
    "            all_streamings += [streaming for streaming in new_streamings]\n",
    "            \n",
    "    #adding datetime field\n",
    "    for streaming in all_streamings:\n",
    "        streaming['datetime'] = datetime.strptime(streaming['endTime'], '%Y-%m-%d %H:%M')    \n",
    "    return all_streamings\n",
    "\n",
    "def get_api_id(track_info: str, token: str,\n",
    "                artist: str = None) -> str:\n",
    "    \n",
    "    '''Performs a query on Spotify API to get a track ID.\n",
    "    See https://curl.trillworks.com/'''\n",
    "\n",
    "    headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer ' + token,\n",
    "    }\n",
    "    track_name = track_info.split(\"___\")[0]\n",
    "    params = [\n",
    "    ('q', track_name),\n",
    "    ('type', 'track'),\n",
    "    ]\n",
    "    artist = track_info.split(\"___\")[-1]\n",
    "    if artist:\n",
    "        params.append(('artist', artist))\n",
    "        \n",
    "    try:\n",
    "        response = requests.get('https://api.spotify.com/v1/search', \n",
    "                    headers = headers, params = params, timeout = 5)\n",
    "        json = response.json()\n",
    "        results = json['tracks']['items']\n",
    "        first_result = json['tracks']['items'][0]\n",
    "        # Check if searched artist is in response as the first one isn't\n",
    "        # necessarily the right one\n",
    "        if artist:\n",
    "            for result in results:\n",
    "                if artist.strip() == result['artists'][0]['name'].strip():\n",
    "                    track_id = result['id']\n",
    "                    return track_id\n",
    "        # If specific artist is not found from results, use the first one\n",
    "        track_id = first_result['id']\n",
    "        return track_id\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def get_saved_ids(tracks, path: str = 'output/track_ids.csv') -> dict:\n",
    "    track_ids = {track: None for track in tracks}\n",
    "    folder, filename = path.split('/')\n",
    "    if filename in listdir(folder):\n",
    "        try:\n",
    "            idd_dataframe = pd.read_csv('output/track_ids.csv', \n",
    "                                     names = ['name', 'idd'])\n",
    "            idd_dataframe = idd_dataframe[1:]                    #removing first row\n",
    "            added_tracks = 0\n",
    "            for index, row in idd_dataframe.iterrows():\n",
    "                if not row[1] == 'nan':                          #if the id is not nan\n",
    "                    track_ids[row[0]] = row[1]                    #add the id to the dict\n",
    "                    added_tracks += 1\n",
    "            print(f'Saved IDs successfully recovered for {added_tracks} tracks.')\n",
    "        except:\n",
    "            print('Error. Failed to recover saved IDs!')\n",
    "            pass\n",
    "    return track_ids\n",
    "    \n",
    "def get_api_features(track_id: str, token: str) -> dict:\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "    try:\n",
    "        features = sp.audio_features([track_id])\n",
    "        return features[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_album(track_id: str, token: str) -> dict:\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "    try:\n",
    "        album = sp.track(track_id)\n",
    "        album_id = album['album']['id']\n",
    "        album_name = album['album']['name']\n",
    "        return album_name, album_id\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def get_saved_features(tracks, path = 'output/features.csv'):\n",
    "    folder, file = path.split('/')\n",
    "    track_features = {track: None for track in tracks}\n",
    "    if file in listdir(folder):\n",
    "        features_df = pd.read_csv(path, index_col = 0)\n",
    "        n_recovered_tracks = 0\n",
    "        for track in features_df.index:\n",
    "            features = features_df.loc[track, :]\n",
    "            if not features.isna().sum():          #if all the features are there\n",
    "                track_features[track] = dict(features)\n",
    "                n_recovered_tracks += 1\n",
    "        print(f\"Added features for {n_recovered_tracks} tracks.\")\n",
    "        return track_features\n",
    "    else:\n",
    "        print(\"Did not find features file.\")\n",
    "        return track_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a519211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import history\n",
    "#import pandas as pd\n",
    "#from time import sleep\n",
    "#from config import *\n",
    "\n",
    "def main():\n",
    "\n",
    "    #recover streamings history\n",
    "    token = history.get_token(username, client_id, \n",
    "                              client_secret, redirect_uri, scope)\n",
    "    \n",
    "    streamings = history.get_streamings()\n",
    "    print(f'Recovered {len(streamings)} streamings.')\n",
    "    \n",
    "    #getting a list of unique tracks in our history\n",
    "    # Add artist names too as multiple artist can have same song name\n",
    "    tracks = set([f\"{streaming['trackName']}___{streaming['artistName']}\" for streaming in streamings])\n",
    "    print(f'Discovered {len(tracks)} unique tracks.')\n",
    "    \n",
    "    #getting saved ids for tracks\n",
    "    track_ids = history.get_saved_ids(tracks)\n",
    "    \n",
    "    #checking tracks that still miss idd\n",
    "    tracks_missing_idd = len([track for track in tracks if track_ids.get(track) is None])\n",
    "    print(f'There are {tracks_missing_idd} tracks missing ID.')\n",
    "    \n",
    "    if tracks_missing_idd > 0:\n",
    "        #using spotify API to recover track ids\n",
    "        #note: this methods works only for tracks. \n",
    "        #podcasts and other items will be ignored.\n",
    "        print('Connecting to Spotify to recover tracks IDs.')\n",
    "        sleep(3)\n",
    "        id_length = 22\n",
    "        for track, idd in track_ids.items(): \n",
    "            if idd is None:\n",
    "                try:\n",
    "                    found_idd = history.get_api_id(track, token)\n",
    "                    track_ids[track] = found_idd\n",
    "                    print(f\"{found_idd:<{id_length}} : {', '.join(track.split('___'))}\")\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        #how many tracks did we identify? \n",
    "        identified_tracks = [track for track in track_ids\n",
    "                         if track_ids[track] is not None]\n",
    "        print(f'Successfully recovered the ID of {len(identified_tracks)} tracks.')\n",
    "        \n",
    "        #how many items did we fail to identify? \n",
    "        n_tracks_without_id = len(track_ids) - len(identified_tracks)\n",
    "        print(f\"Failed to identify {n_tracks_without_id} items. \"\n",
    "              \"However, some of these may not be tracks (e.g. podcasts).\")\n",
    "        \n",
    "        #using pandas to save tracks ids (so we don't have to API them in the future)\n",
    "        ids_path = 'output/track_ids.csv'\n",
    "        ids_dataframe = pd.DataFrame.from_dict(track_ids, \n",
    "                                               orient = 'index')\n",
    "        ids_dataframe.to_csv(ids_path)\n",
    "        print(f'track ids saved to {ids_path}.')\n",
    "    \n",
    "    #recovering saved features\n",
    "    track_features = history.get_saved_features(tracks)\n",
    "    tracks_without_features = [track for track in tracks if track_features.get(track) is None]\n",
    "    print(f\"There are still {len(tracks_without_features)} tracks without features.\")\n",
    "    path = 'output/features.csv'\n",
    "    \n",
    "    #connecting to spotify API to retrieve missing features\n",
    "    if len (tracks_without_features):\n",
    "        print('Connecting to Spotify to extract features...')\n",
    "        acquired = 0\n",
    "        for track, idd in track_ids.items():\n",
    "            if idd is not None and track in tracks_without_features:\n",
    "                try:\n",
    "                    features = history.get_api_features(idd, token)\n",
    "                    track_features[track] = features\n",
    "                    features['albumName'], features['albumID'] = history.get_album(idd, token)\n",
    "                    if features:\n",
    "                        acquired += 1\n",
    "                        print(f\"Acquired features: {', '.join(track.split('___'))}. Total: {acquired}\")\n",
    "                except:\n",
    "                    features = None\n",
    "        tracks_without_features = [track for track in tracks if track_features.get(track) is None]\n",
    "        print(f'Successfully recovered features of {acquired} tracks.')\n",
    "        if len(tracks_without_features):\n",
    "            print(f'Failed to identify {len(tracks_without_features)} items. Some of these may not be tracks.')\n",
    "        \n",
    "        #saving features \n",
    "        features_dataframe = pd.DataFrame(track_features).T\n",
    "        features_dataframe.to_csv(path)\n",
    "        print(f'Saved features to {path}.')\n",
    "    \n",
    "    #joining features and streamings\n",
    "    print('Adding features to streamings...')\n",
    "    streamings_with_features = []\n",
    "    for streaming in sorted(streamings, key= lambda x: x['endTime']):\n",
    "        track = streaming['trackName'] + \"___\" + streaming['artistName']\n",
    "        features = track_features.get(track)\n",
    "        if features:\n",
    "            streamings_with_features.append({'name': track, **streaming, **features})\n",
    "    print(f'Added features to {len(streamings_with_features)} streamings.')\n",
    "    print('Saving streamings...')\n",
    "    df_final = pd.DataFrame(streamings_with_features)\n",
    "    df_final.to_csv('output/final.csv')\n",
    "    perc_featured = round(len(streamings_with_features) / len(streamings) *100, 2)\n",
    "    print(f\"Done! Percentage of streamings with features: {perc_featured}%.\") \n",
    "    print(\"Run the script again to try getting more information from Spotify.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = []\n",
    "track_name = []\n",
    "track_popularity = []\n",
    "artist_id = []\n",
    "track_id = []\n",
    "for i in range(0,1000):\n",
    "    track_results = sp.search(q='year:2023', type='track', limit=50,offset=i)\n",
    "    for i, t in enumerate(track_results['tracks']['items']):\n",
    "        artist_name.append(t['artists'][0]['name'])\n",
    "        artist_id.append(t['artists'][0]['id'])\n",
    "        track_name.append(t['name'])\n",
    "        track_id.append(t['id'])\n",
    "        track_popularity.append(t['popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4728021",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df = pd.DataFrame({'artist_name' : artist_name, 'track_name' : track_name, 'track_id' : track_id, 'track_popularity' : track_popularity, 'artist_id' : artist_id})\n",
    "print(track_df.shape)\n",
    "track_df_pop = track_df.sort_values(\"track_popularity\", ascending=False)\n",
    "track_df_pop.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df_pop_no_d = track_df_pop.drop_duplicates(\"track_id\")\n",
    "print(track_df_pop_no_d.shape)\n",
    "track_df_pop_no_d.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
